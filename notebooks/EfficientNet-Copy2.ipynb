{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "still-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten\n",
    "from tensorflow.keras.applications import EfficientNetB0, Xception\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "headed-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "designing-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improved-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"train_images/\"\n",
    "#train['full_filepath'] = path + train.chain.astype(str) +\"/\"+ train.image.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adult-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "miniature-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.iloc[0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "refined-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[train.chain.isin([0,1,2])]\n",
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medium-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_subsample = 5000\n",
    "#train = train.sample(n_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parallel-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, = train_test_split(train, test_size = 0.30,\n",
    "#    stratify = train['chain'], shuffle = True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welcome-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape)\n",
    "#print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "composite-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes = X_train.chain.nunique()\n",
    "\n",
    "#BATCH_SIZE = 64\n",
    "#STEPS_PER_EPOCH = len(X_train) // BATCH_SIZE\n",
    "EPOCHS = 50\n",
    "\n",
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "offshore-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass HotelBatchSequence(tf.keras.utils.Sequence):\\n    \\n    def __init__(self, x_set, y_set, batch_size,\\n                 img_size = (224, 224),\\n                 augment = False):\\n        \"\"\"\\n        `x_set` is list of paths to the images\\n        `y_set` are the associated classes.\\n\\n        \"\"\"\\n        \\n        self.x = x_set\\n        self.y = y_set\\n        self.batch_size = batch_size\\n        self.img_size = img_size\\n    \\n    def __len__(self):\\n        \"\"\"Denotes the number of batches per epoch\"\"\"\\n        return math.ceil(len(self.x) / self.batch_size)\\n    \\n    def __getitem__(self, idx):\\n        \"\"\"Generate one batch of data\"\"\"\\n        \\n        first_id = idx * self.batch_size\\n        last_id =  (idx + 1) * (self.batch_size)\\n        \\n        batch_x = self.x[first_id:last_id]\\n        batch_y = self.y[first_id:last_id]\\n        \\n        #Xs = np.array([resize(imread(file_name), self.img_size)\\n        #      for file_name in batch_x])\\n        # \\n        #ys = np.array(batch_y)\\n        \\n        output = np.array([\\n            resize(cv2.imread(file_name), self.img_size)\\n                   for file_name in batch_x]), np.array(batch_y)\\n        \\n        return output\\n        \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class HotelBatchSequence(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, x_set, y_set, batch_size,\n",
    "                 img_size = (224, 224),\n",
    "                 augment = False):\n",
    "        \"\"\"\n",
    "        `x_set` is list of paths to the images\n",
    "        `y_set` are the associated classes.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Generate one batch of data\"\"\"\n",
    "        \n",
    "        first_id = idx * self.batch_size\n",
    "        last_id =  (idx + 1) * (self.batch_size)\n",
    "        \n",
    "        batch_x = self.x[first_id:last_id]\n",
    "        batch_y = self.y[first_id:last_id]\n",
    "        \n",
    "        #Xs = np.array([resize(imread(file_name), self.img_size)\n",
    "        #      for file_name in batch_x])\n",
    "        # \n",
    "        #ys = np.array(batch_y)\n",
    "        \n",
    "        output = np.array([\n",
    "            resize(cv2.imread(file_name), self.img_size)\n",
    "                   for file_name in batch_x]), np.array(batch_y)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stylish-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTrainGenerator = HotelBatchSequence(X_train.full_filepath, \\n                                    tf.keras.utils.to_categorical(X_train.chain),\\n                                    BATCH_SIZE)\\n\\nValidGenerator = HotelBatchSequence(X_val.full_filepath, \\n                                   tf.keras.utils.to_categorical(X_val.chain),\\n                                   BATCH_SIZE)\\n                                   '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TrainGenerator = HotelBatchSequence(X_train.full_filepath, \n",
    "                                    tf.keras.utils.to_categorical(X_train.chain),\n",
    "                                    BATCH_SIZE)\n",
    "\n",
    "ValidGenerator = HotelBatchSequence(X_val.full_filepath, \n",
    "                                   tf.keras.utils.to_categorical(X_val.chain),\n",
    "                                   BATCH_SIZE)\n",
    "                                   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "labeled-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51787 images belonging to 87 classes.\n",
      "Found 25508 images belonging to 87 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_generator = train_datagen.flow_from_directory(\\n        'data3/train',  # this is the target directory\\n        target_size=(224, 224),  # all images will be resized to 150x150\\n        batch_size=batch_size,\\n        class_mode='categorical')\\n\\ntest_generator = test_datagen.flow_from_directory(\\n        'data3/test',\\n        target_size=(224, 224),\\n        batch_size=batch_size,\\n        class_mode='categorical')\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'newimages/train',  # this is the target directory\n",
    "        target_size=(299, 299),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'newimages/test',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data3/train',  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data3/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shared-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_batch=TrainGenerator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "retired-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "former-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "consistent-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "91889664/91884032 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "efficientnet = Xception(include_top=True,\n",
    "                             weights='imagenet',\n",
    "                             input_shape=(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "                              \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "searching-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten1= Flatten()(efficientnet.output)\n",
    "output = Dense(87, activation='softmax')(flatten1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "polyphonic-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=efficientnet.input,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "correct-connectivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "functional-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = efficientnet\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "crude-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass SGDR(tf.keras.callbacks.Callback):\\n \\n\\n    def __init__(self, min_lr=0.0, max_lr=0.05, base_epochs=10, mul_epochs=2):\\n        super(SGDR, self).__init__()\\n\\n        self.min_lr = min_lr\\n        self.max_lr = max_lr\\n        self.base_epochs = base_epochs\\n        self.mul_epochs = mul_epochs\\n\\n        self.cycles = 0.\\n        self.cycle_iterations = 0.\\n        self.trn_iterations = 0.\\n\\n        self._reset()\\n\\n    def _reset(self, new_min_lr=None, new_max_lr=None,\\n               new_base_epochs=None, new_mul_epochs=None):\\n        \"\"\"Resets cycle iterations.\"\"\"\\n        \\n        if new_min_lr != None:\\n            self.min_lr = new_min_lr\\n        if new_max_lr != None:\\n            self.max_lr = new_max_lr\\n        if new_base_epochs != None:\\n            self.base_epochs = new_base_epochs\\n        if new_mul_epochs != None:\\n            self.mul_epochs = new_mul_epochs\\n        self.cycles = 0.\\n        self.cycle_iterations = 0.\\n        \\n    def sgdr(self):\\n        \\n        cycle_epochs = self.base_epochs * (self.mul_epochs ** self.cycles)\\n        return self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(np.pi * (self.cycle_iterations + 1) / cycle_epochs))\\n        \\n    def on_train_begin(self, logs=None):\\n        \\n        if self.cycle_iterations == 0:\\n            K.set_value(self.model.optimizer.lr, self.max_lr)\\n        else:\\n            K.set_value(self.model.optimizer.lr, self.sgdr())\\n            \\n    def on_epoch_end(self, epoch, logs=None):\\n        \\n        logs = logs or {}\\n        logs[\\'lr\\'] = K.get_value(self.model.optimizer.lr)\\n        \\n        self.trn_iterations += 1\\n        self.cycle_iterations += 1\\n        if self.cycle_iterations >= self.base_epochs * (self.mul_epochs ** self.cycles):\\n            self.cycles += 1\\n            self.cycle_iterations = 0\\n            K.set_value(self.model.optimizer.lr, self.max_lr)\\n        else:\\n            K.set_value(self.model.optimizer.lr, self.sgdr())\\n            '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class SGDR(tf.keras.callbacks.Callback):\n",
    " \n",
    "\n",
    "    def __init__(self, min_lr=0.0, max_lr=0.05, base_epochs=10, mul_epochs=2):\n",
    "        super(SGDR, self).__init__()\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.base_epochs = base_epochs\n",
    "        self.mul_epochs = mul_epochs\n",
    "\n",
    "        self.cycles = 0.\n",
    "        self.cycle_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_min_lr=None, new_max_lr=None,\n",
    "               new_base_epochs=None, new_mul_epochs=None):\n",
    "        \"\"\"Resets cycle iterations.\"\"\"\n",
    "        \n",
    "        if new_min_lr != None:\n",
    "            self.min_lr = new_min_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_base_epochs != None:\n",
    "            self.base_epochs = new_base_epochs\n",
    "        if new_mul_epochs != None:\n",
    "            self.mul_epochs = new_mul_epochs\n",
    "        self.cycles = 0.\n",
    "        self.cycle_iterations = 0.\n",
    "        \n",
    "    def sgdr(self):\n",
    "        \n",
    "        cycle_epochs = self.base_epochs * (self.mul_epochs ** self.cycles)\n",
    "        return self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(np.pi * (self.cycle_iterations + 1) / cycle_epochs))\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \n",
    "        if self.cycle_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.sgdr())\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "        \n",
    "        self.trn_iterations += 1\n",
    "        self.cycle_iterations += 1\n",
    "        if self.cycle_iterations >= self.base_epochs * (self.mul_epochs ** self.cycles):\n",
    "            self.cycles += 1\n",
    "            self.cycle_iterations = 0\n",
    "            K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.sgdr())\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-january",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "christian-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 537/5179 [==>...........................] - ETA: 1:06:53 - loss: 4.0804 - accuracy: 0.1035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/PIL/Image.py:2850: DecompressionBombWarning: Image size (108576768 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5179/5179 [==============================] - 5692s 1s/step - loss: 3.6733 - accuracy: 0.1056 - val_loss: 3.5806 - val_accuracy: 0.1055\n",
      "Epoch 2/10\n",
      "5179/5179 [==============================] - 5642s 1s/step - loss: 3.5796 - accuracy: 0.1055 - val_loss: 3.5774 - val_accuracy: 0.1055\n",
      "Epoch 3/10\n",
      "5179/5179 [==============================] - 5641s 1s/step - loss: 3.5783 - accuracy: 0.1055 - val_loss: 3.5774 - val_accuracy: 0.1055\n",
      "Epoch 4/10\n",
      "5179/5179 [==============================] - 5646s 1s/step - loss: 3.5782 - accuracy: 0.1055 - val_loss: 3.5774 - val_accuracy: 0.1055\n",
      "Epoch 5/10\n",
      "5179/5179 [==============================] - 5624s 1s/step - loss: 3.5784 - accuracy: 0.1055 - val_loss: 3.5773 - val_accuracy: 0.1055\n",
      "Epoch 6/10\n",
      "5179/5179 [==============================] - 5604s 1s/step - loss: 3.5783 - accuracy: 0.1055 - val_loss: 3.5774 - val_accuracy: 0.1055\n",
      "Epoch 7/10\n",
      "5179/5179 [==============================] - 5651s 1s/step - loss: 3.5784 - accuracy: 0.1055 - val_loss: 3.5774 - val_accuracy: 0.1055\n",
      "Epoch 8/10\n",
      "5179/5179 [==============================] - 5655s 1s/step - loss: 3.5782 - accuracy: 0.1055 - val_loss: 3.5775 - val_accuracy: 0.1055\n",
      "Epoch 9/10\n",
      "5179/5179 [==============================] - 5635s 1s/step - loss: 3.5783 - accuracy: 0.1055 - val_loss: 3.5772 - val_accuracy: 0.1055\n",
      "Epoch 10/10\n",
      "5179/5179 [==============================] - 5659s 1s/step - loss: 3.5784 - accuracy: 0.1055 - val_loss: 3.5772 - val_accuracy: 0.1055\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                 #   steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_data = test_generator,\n",
    "                  #  validation_split=.10,\n",
    "                    workers = -1,\n",
    "                    epochs = 10,\n",
    "                    use_multiprocessing = False,\n",
    "                    max_queue_size = 10\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('eff_net1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(history, KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-watershed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
